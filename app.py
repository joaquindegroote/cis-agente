import os
import json
import time
import hashlib
import pickle
from pathlib import Path
from typing import List, Dict, Any, Optional

import numpy as np
import streamlit as st

# --- OpenAI SDK (v1) ---
try:
    from openai import OpenAI
except ImportError:
    st.error("Falta el paquete 'openai'. Instala requirements.txt")
    st.stop()

# ========================================
# CONFIGURACI√ìN
# ========================================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
MODEL_CHAT = os.getenv("OPENAI_MODEL_CHAT", "gpt-5-mini-2025-08-07")
MODEL_EMB = os.getenv("OPENAI_MODEL_EMB", "text-embedding-3-large")

PROJECTS_PATH = os.getenv("PROJECTS_JSON", "projects.json")
TOP_K_DEFAULT = 2
EMBEDDING_BATCH_SIZE = 64
CANDIDATE_POOL_SIZE = 4  # Cu√°ntos candidatos enviamos a GPT para re-ranking

# ========================================
# CONSTANTES DE FORMULARIO
# ========================================
AREAS = ["Estrategia", "Personas", "Operaciones"]

CATEGORIAS = {
    "Estrategia": [
        "Modelo de Negocio",
        "Estrategia de Negocio",
        "Gobierno Corporativo",
        "Gesti√≥n de Proyectos",
        "Estrategia Corporativa",
        "Otro"
    ],
    "Personas": [
        "Gesti√≥n del Talento",
        "Desarrollo Organizacional",
        "Cultura y Clima",
        "Compensaciones",
        "Otro"
    ],
    "Operaciones": [
        "Procesos",
        "Supply Chain",
        "Eficiencia Operacional",
        "Transformaci√≥n Digital",
        "Otro"
    ]
}

INDUSTRIAS = [
    "Inmobiliario",
    "Entretenimiento",
    "Construcci√≥n",
    "Alimentaci√≥n",
    "Industria Qu√≠mica",
    "Reciclaje",
    "Movilidad",
    "Desarrollo Tecnol√≥gico",
    "Manufactura",
    "Servicios Jur√≠dicos",
    "Miner√≠a",
    "Industria",
    "Ferreter√≠a",
    "Tecnolog√≠a de la informaci√≥n y Comunicaciones (TIC's)",
    "Servicios Profesionales",
    "Otro"
]

DURACIONES = [
    "Menos de 3 meses",
    "Entre 3-6 meses",
    "Entre 6-12 meses",
    "M√°s de 12 meses"
]

ENTREGABLES = [
    "Roadmap",
    "Diagn√≥stico",
    "Plan de implementaci√≥n",
    "Carta Gantt",
    "Modelo de negocio",
    "An√°lisis financiero"
]

ENFOQUES = [
    "Diagn√≥stico",
    "Dise√±o",
    "Implementaci√≥n"
]

# ========================================
# COLORES CIS
# ========================================
CIS = {
    "rojo": "#F20034",
    "negro": "#111111",
    "blanco": "#FFFFFF",
    "gris_osc": "#1F2937",
    "gris_intermedio": "#6B7280",
    "gris_claro": "#F3F4F6",
    "turquesa": "#005670",
    "celeste": "#9BB3BC",
    "rojo_claro": "#DB5D71",
    "gris_osc_2": "#374151",
    "link": "#0F766E"
}

# ========================================
# FUNCIONES DE UTILIDAD
# ========================================

def css_cis():
    """Estilos CSS mejorados con mejor contraste y fuentes m√°s grandes"""
    st.markdown(
        """
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap');

        /* BASE - Fuentes m√°s grandes */
        html, body, [class*="css"] {
          font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif !important;
          color: #FFFFFF !important;
          background: #0E1117;
          font-size: 18px !important;
          line-height: 1.7;
          -webkit-font-smoothing: antialiased;
        }

        .main .block-container {
          padding: 2.5rem 3rem 3rem 3rem !important;
          max-width: 1400px !important;
        }
        
        .stApp {
          background: #0E1117 !important;
        }
        
        /* T√≠tulos con mejor contraste */
        .main h1, .main h2, .main h3 {
          color: #FFFFFF !important;
          font-weight: 700 !important;
        }
        .main h1 {
          font-size: 2.2rem !important;
        }
        .main h2 {
          font-size: 1.7rem !important;
        }
        .main h3 {
          font-size: 1.4rem !important;
        }
        
        /* Labels de formulario - BLANCOS y m√°s grandes */
        label[data-testid="stWidgetLabel"] {
          color: #FFFFFF !important;
          font-weight: 700 !important;
          font-size: 1.15rem !important;
          background: rgba(0, 86, 112, 0.3) !important;
          padding: 0.5rem 0.9rem !important;
          border-radius: 8px !important;
          display: inline-block !important;
          margin-bottom: 0.6rem !important;
          border-left: 4px solid #005670 !important;
        }

        /* Sidebar SIMPLIFICADO - Fondo oscuro con texto blanco */
        section[data-testid="stSidebar"] {
          background: #1a1d24 !important;
          border-right: 2px solid #005670 !important;
          padding-top: 2rem !important;
        }
        section[data-testid="stSidebar"] > div {
          padding: 0 1.5rem !important;
        }
        section[data-testid="stSidebar"] h2, 
        section[data-testid="stSidebar"] h3,
        section[data-testid="stSidebar"] h4 {
          color: #FFFFFF !important;
          font-weight: 700 !important;
          font-size: 1.3rem !important;
          margin-bottom: 1.2rem !important;
          letter-spacing: -0.02em;
        }
        section[data-testid="stSidebar"] .stMarkdown,
        section[data-testid="stSidebar"] p,
        section[data-testid="stSidebar"] label,
        section[data-testid="stSidebar"] span,
        section[data-testid="stSidebar"] div {
          color: #E5E7EB !important;
          font-size: 1.05rem !important;
        }
        section[data-testid="stSidebar"] label[data-testid="stWidgetLabel"] {
          color: #FFFFFF !important;
          font-weight: 600 !important;
          font-size: 1.1rem !important;
        }
        section[data-testid="stSidebar"] .stCaption {
          color: #9CA3AF !important;
          font-size: 0.95rem !important;
        }

        /* Header principal */
        .cis-header {
          background: linear-gradient(135deg, #005670 0%, #007A94 100%);
          color: white;
          padding: 2.2rem 2.8rem;
          border-radius: 16px;
          margin-bottom: 2rem;
          box-shadow: 0 4px 6px rgba(0, 86, 112, 0.1), 0 2px 4px rgba(0, 86, 112, 0.06);
        }
        .cis-header h1 {
          color: white !important;
          font-size: 2.3rem !important;
          font-weight: 800 !important;
          margin: 0 0 0.5rem 0 !important;
          letter-spacing: -0.03em;
        }
        .cis-header p {
          color: rgba(255, 255, 255, 0.95) !important;
          font-size: 1.15rem !important;
          margin: 0;
          font-weight: 400;
        }

        /* Info box con mejor contraste */
        .cis-info-box {
          background: rgba(0, 86, 112, 0.15);
          border: 2px solid #005670;
          border-left: 5px solid #005670;
          border-radius: 12px;
          padding: 1.5rem 1.75rem;
          margin: 1.5rem 0;
          box-shadow: 0 1px 3px rgba(0, 86, 112, 0.2);
        }
        .cis-info-box strong {
          color: #FFFFFF !important;
          font-weight: 700;
          font-size: 1.2rem !important;
        }
        .cis-info-box p {
          color: #E5E7EB !important;
          font-size: 1.05rem !important;
        }

        /* Dividers m√°s visibles */
        .main hr {
          background: linear-gradient(90deg, transparent, #6B7280 50%, transparent) !important;
          margin: 2rem 0 !important;
          opacity: 0.7;
          height: 2px !important;
        }

        /* Tarjetas de resultado con mejor contraste */
        .cis-result-card {
          background: #1F2937 !important;
          border: 2px solid #374151 !important;
          border-radius: 14px;
          padding: 2rem 2.3rem;
          margin-bottom: 1.8rem;
          box-shadow: 0 3px 6px rgba(0, 0, 0, 0.2);
          transition: all 0.2s ease;
          position: relative;
          overflow: hidden;
        }
        .cis-result-card::before {
          content: '';
          position: absolute;
          left: 0;
          top: 0;
          bottom: 0;
          width: 6px;
          background: linear-gradient(180deg, #005670 0%, #00A0D2 100%);
        }
        .cis-result-card:hover {
          box-shadow: 0 6px 14px rgba(0, 0, 0, 0.3);
          transform: translateY(-2px);
          border-color: #005670 !important;
        }

        /* T√≠tulo cliente - M√ÅS VISIBLE */
        .cis-client-name {
          color: #00D4FF !important;
          font-size: 1.6rem !important;
          font-weight: 800 !important;
          margin: 0 0 0.7rem 0;
          letter-spacing: -0.02em;
        }

        /* Metadata - TEXTO BLANCO */
        .cis-meta-item {
          color: #FFFFFF !important;
          font-size: 1.1rem !important;
          margin: 0.5rem 0;
          display: flex;
          align-items: baseline;
          line-height: 1.6;
        }
        .cis-meta-item strong {
          color: #9BB3BC !important;
          font-weight: 700 !important;
          min-width: 160px;
          font-size: 1.1rem !important;
        }

        /* Badge de GPT Score */
        .gpt-badge {
          display: inline-block;
          background: linear-gradient(135deg, #F20034 0%, #C70028 100%);
          color: white;
          padding: 0.4rem 0.8rem;
          border-radius: 6px;
          font-weight: 800;
          font-size: 1rem;
          margin-left: 0.5rem;
          box-shadow: 0 2px 4px rgba(242, 0, 52, 0.3);
        }

        /* Reasoning box */
        .gpt-reasoning {
          background: rgba(242, 0, 52, 0.08);
          border: 2px solid rgba(242, 0, 52, 0.3);
          border-left: 4px solid #F20034;
          border-radius: 10px;
          padding: 1rem 1.3rem;
          margin: 1rem 0;
        }
        .gpt-reasoning strong {
          color: #FF4D6D !important;
          font-size: 1.05rem !important;
        }
        .gpt-reasoning p {
          color: #E5E7EB !important;
          margin: 0.3rem 0 0 0;
          font-size: 1rem !important;
        }
        .gpt-reasoning ul {
          margin: 0.5rem 0;
          padding-left: 1.5rem;
        }
        .gpt-reasoning li {
          color: #E5E7EB !important;
          margin: 0.3rem 0;
        }

        /* Secci√≥n econ√≥mica con mejor contraste */
        .cis-economic-box {
          background: rgba(0, 86, 112, 0.15);
          border: 2px solid #005670;
          border-radius: 10px;
          padding: 1.2rem 1.4rem;
          margin: 1.2rem 0;
        }
        .cis-economic-box strong {
          color: #00D4FF !important;
          font-size: 1.15rem !important;
        }
        .cis-economic-box div {
          font-size: 1.05rem !important;
          color: #FFFFFF !important;
        }

        /* Extracto t√©cnico - TEXTO BLANCO */
        .cis-excerpt {
          color: #FFFFFF !important;
          font-size: 1.05rem !important;
          line-height: 1.7;
          padding: 1.2rem;
          background: rgba(0, 86, 112, 0.1);
          border-radius: 10px;
          margin: 1.2rem 0;
          border-left: 4px solid #9BB3BC;
        }
        .cis-excerpt strong {
          color: #00D4FF !important;
          display: block;
          margin-bottom: 0.5rem;
        }

        /* Enlaces con mejor contraste */
        .cis-links {
          margin-top: 1.4rem;
          padding-top: 1.2rem;
          border-top: 2px solid #374151;
          display: flex;
          gap: 1.2rem;
          flex-wrap: wrap;
        }
        .cis-links a {
          color: white !important;
          background: #005670 !important;
          text-decoration: none !important;
          font-weight: 700 !important;
          font-size: 1.05rem !important;
          padding: 0.75rem 1.5rem !important;
          border-radius: 8px !important;
          transition: all 0.2s ease !important;
          display: inline-flex !important;
          align-items: center !important;
          border: 2px solid #005670 !important;
        }
        .cis-links a:hover {
          background: #003D4D !important;
          border-color: #00D4FF !important;
          transform: translateY(-2px) !important;
          box-shadow: 0 4px 10px rgba(0, 212, 255, 0.3) !important;
        }

        /* Box "Por qu√©" con mejor contraste */
        .cis-why-box {
          background: rgba(242, 0, 52, 0.1);
          border: 2px solid #F20034;
          border-left: 6px solid #F20034;
          border-radius: 12px;
          padding: 1.7rem 2rem;
          margin: 2rem 0;
          box-shadow: 0 3px 6px rgba(242, 0, 52, 0.15);
        }
        .cis-why-box strong {
          color: #FF4D6D !important;
          font-size: 1.25rem !important;
          display: block;
          margin-bottom: 0.9rem;
          font-weight: 800 !important;
        }
        .cis-why-box p {
          color: #FFFFFF !important;
          margin: 0;
          line-height: 1.7;
          font-size: 1.05rem !important;
        }

        /* Bot√≥n principal m√°s grande */
        .stButton > button {
          background: linear-gradient(135deg, #F20034 0%, #C70028 100%) !important;
          color: white !important;
          border: none !important;
          border-radius: 10px !important;
          padding: 1rem 3rem !important;
          font-weight: 700 !important;
          font-size: 1.15rem !important;
          box-shadow: 0 4px 8px rgba(242, 0, 52, 0.3) !important;
          transition: all 0.2s ease !important;
        }
        .stButton > button:hover {
          transform: translateY(-2px) !important;
          box-shadow: 0 6px 16px rgba(242, 0, 52, 0.4) !important;
        }

        /* Inputs con mejor contraste */
        .stTextArea textarea, .stTextInput input {
          border: 2px solid #374151 !important;
          border-radius: 8px !important;
          padding: 1rem !important;
          font-size: 1.05rem !important;
          background: #1F2937 !important;
          color: #FFFFFF !important;
        }
        .stTextArea textarea:focus, .stTextInput input:focus {
          border-color: #005670 !important;
          box-shadow: 0 0 0 3px rgba(0, 86, 112, 0.2) !important;
        }
        .stTextArea textarea::placeholder,
        .stTextInput input::placeholder {
          color: #9CA3AF !important;
          opacity: 1 !important;
        }

        /* Multiselect y Selectbox con mejor contraste */
        .stMultiSelect, .stSelectbox {
          margin: 0.6rem 0;
        }
        .stMultiSelect div[data-baseweb="select"] > div,
        .stSelectbox div[data-baseweb="select"] > div {
          color: #FFFFFF !important;
          font-size: 1.05rem !important;
          background: #1F2937 !important;
          border: 2px solid #374151 !important;
        }
        div[role="listbox"] li {
          color: #0B0B0B !important;
          font-size: 1.05rem !important;
        }

        /* Checkbox m√°s visible */
        .stCheckbox {
          background: rgba(242, 0, 52, 0.1) !important;
          padding: 0.7rem 1rem !important;
          border-radius: 8px !important;
          margin: 1rem 0 !important;
          border-left: 4px solid #F20034 !important;
        }
        .stCheckbox label {
          color: #FFFFFF !important;
          font-weight: 700 !important;
          font-size: 1.15rem !important;
        }
        
        /* Markdown text visible */
        .main .stMarkdown {
          color: #FFFFFF !important;
        }
        .main .stMarkdown p {
          color: #E5E7EB !important;
        }

        /* Radio buttons m√°s grandes */
        .stRadio > label {
          font-size: 1.1rem !important;
          color: #FFFFFF !important;
        }
        .stRadio div[role="radiogroup"] label {
          font-size: 1.05rem !important;
          color: #E5E7EB !important;
        }

        /* Sliders m√°s visibles */
        .stSlider {
          padding: 0.5rem 0 !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )


def load_projects(path: str) -> List[Dict[str, Any]]:
    """Carga el archivo JSON de proyectos"""
    p = Path(path)
    if not p.exists():
        st.error(f"‚ùå No encontr√© el archivo {path}. Aseg√∫rate de tener projects.json en la carpeta del proyecto.")
        st.stop()
    
    try:
        content = p.read_text(encoding="utf-8")
        projects = json.loads(content)
        
        if not isinstance(projects, list):
            st.error("‚ùå El archivo JSON debe contener una lista de proyectos")
            st.stop()
            
        return projects
    except json.JSONDecodeError as e:
        st.error(f"‚ùå Error al parsear JSON: {e}")
        st.stop()


def normalize_text(x: str) -> str:
    """Normaliza espacios en blanco en texto"""
    return " ".join((x or "").split())


def project_text_for_embedding(p: Dict[str, Any]) -> str:
    """Construye el texto representativo de un proyecto para generar embeddings"""
    parts = [
        str(p.get("nombre_proyecto") or ""),
        str(p.get("industria") or ""),
        str(p.get("catalogacion") or ""),
        str(p.get("area_negocio") or ""),
        normalize_text(p.get("objetivo_general") or ""),
        normalize_text(p.get("objetivos_especificos") or ""),
    ]
    return "\n".join([t for t in parts if t]).strip()


def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
    """Calcula similitud de coseno entre dos vectores"""
    denom = (np.linalg.norm(a) * np.linalg.norm(b))
    return float(np.dot(a, b) / denom) if denom else 0.0


def emb_cache_key(texts: List[str]) -> str:
    """Genera clave de cach√© basada en el corpus de texto"""
    h = hashlib.sha256()
    for t in texts:
        h.update((t + "\n").encode("utf-8"))
    h.update(MODEL_EMB.encode())
    return h.hexdigest()[:16]


def embed_texts(client: OpenAI, texts: List[str]) -> np.ndarray:
    """Genera embeddings usando la API de OpenAI"""
    try:
        resp = client.embeddings.create(model=MODEL_EMB, input=texts)
        vecs = [np.array(d.embedding, dtype=np.float32) for d in resp.data]
        return np.vstack(vecs)
    except Exception as e:
        st.error(f"‚ùå Error al generar embeddings: {e}")
        raise


def ensure_embeddings(client: OpenAI, projects: List[Dict[str, Any]]) -> np.ndarray:
    """Genera o carga embeddings desde cach√©"""
    corpus = [project_text_for_embedding(p) for p in projects]
    key = emb_cache_key(corpus)
    cache_file = Path(f".emb_cache_{key}.pkl")
    
    if cache_file.exists():
        try:
            return pickle.loads(cache_file.read_bytes())
        except Exception as e:
            st.warning(f"‚ö†Ô∏è No se pudo cargar cach√© de embeddings: {e}. Regenerando...")
    
    vecs = []
    for i in range(0, len(corpus), EMBEDDING_BATCH_SIZE):
        chunk = corpus[i:i + EMBEDDING_BATCH_SIZE]
        chunk = [c if c.strip() else " " for c in chunk]
        v = embed_texts(client, chunk)
        vecs.append(v)
        time.sleep(0.05)
    
    mat = np.vstack(vecs) if vecs else np.zeros((0, 3072))
    
    try:
        cache_file.write_bytes(pickle.dumps(mat))
    except Exception as e:
        st.warning(f"‚ö†Ô∏è No se pudo guardar cach√© de embeddings: {e}")
    
    return mat


def llm_rerank_projects(
    client: OpenAI, 
    user_prompt: str, 
    candidates: List[tuple], 
    top_k: int
) -> List[Dict[str, Any]]:
    """
    Usa GPT-5 para analizar y re-rankear proyectos con razonamiento estrat√©gico
    """
    
    # Preparar candidatos para GPT
    candidatos_texto = []
    for idx, (proj_idx, semantic_score, p) in enumerate(candidates, 1):
        objetivo_general = (p.get("objetivo_general") or "")[:300]
        objetivos_especificos = (p.get("objetivos_especificos") or "")[:200]
        
        candidatos_texto.append(f"""
CANDIDATO {idx} | Similitud Sem√°ntica: {semantic_score:.1%}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚Ä¢ Cliente: {p.get('nombre_cliente', 'N/A')}
‚Ä¢ Proyecto: {p.get('nombre_proyecto', 'N/A')}
‚Ä¢ Industria: {p.get('industria', 'N/A')}
‚Ä¢ √Årea: {p.get('area_negocio', 'N/A')}
‚Ä¢ Categorizaci√≥n: {p.get('catalogacion', 'N/A')}
‚Ä¢ A√±o: {p.get('anio', 'N/A')}
‚Ä¢ Objetivo General: {objetivo_general}
‚Ä¢ Objetivos Espec√≠ficos: {objetivos_especificos}
""")
    
    system_prompt = f"""Eres un consultor estrat√©gico senior de CIS con 20+ a√±os de experiencia en matching de proyectos de consultor√≠a.

Tu tarea es ANALIZAR y RE-RANKEAR los {len(candidates)} proyectos candidatos seg√∫n su RELEVANCIA ESTRAT√âGICA REAL para el requerimiento del cliente.

CRITERIOS DE EVALUACI√ìN (ponderados):
1. **Transferibilidad de Objetivos** (40%): ¬øLos desaf√≠os de negocio y metas son genuinamente comparables y aplicables?
2. **Contexto de Industria** (25%): ¬øEl sector, mercado y din√°micas de negocio son transferibles?
3. **Aplicabilidad Metodol√≥gica** (20%): ¬øLas metodolog√≠as, enfoques y herramientas usadas son replicables?
4. **Alineaci√≥n de Categor√≠a** (15%): ¬øEl tipo de proyecto y √°rea de consultor√≠a son consistentes?

PRINCIPIOS DE RAZONAMIENTO:
‚úì PRIORIZA proyectos con aprendizajes genuinamente transferibles, no solo similitud superficial
‚úì VALORA industrias relacionadas (ej: Retail ‚âà Alimentaci√≥n) sobre matches exactos sin aplicabilidad
‚úì CONSIDERA trade-offs estrat√©gicos (mejor industria vs mejor metodolog√≠a)
‚úì DESCARTA proyectos con similitud sem√°ntica alta pero contexto de negocio incompatible
‚úì IDENTIFICA fortalezas espec√≠ficas (qu√© hace valioso este match) y debilidades (qu√© limitaciones tiene)

RESPONDE EN JSON ESTRICTO con este formato EXACTO:
{{
  "top_projects": [
    {{
      "candidato_numero": 1,
      "score_final": 95,
      "razon_principal": "Match excepcional: industria id√©ntica, objetivos de transformaci√≥n digital altamente transferibles y metodolog√≠a probada en contexto similar",
      "fortalezas": [
        "Industria y segmento de mercado id√©nticos",
        "Objetivos de negocio altamente alineados con enfoque en digitalizaci√≥n",
        "Metodolog√≠a de design thinking aplicable directamente"
      ],
      "debilidades": [
        "Alcance del proyecto original menor al requerimiento actual",
        "No aborda espec√≠ficamente el componente de analytics mencionado"
      ]
    }}
  ],
  "analisis_general": "Breve an√°lisis de patrones encontrados en el matching (2-3 l√≠neas)"
}}

CR√çTICO: 
- Responde SOLO con JSON v√°lido, sin markdown ni texto adicional
- Incluye EXACTAMENTE {top_k} proyectos en top_projects
- Cada score_final debe ser un n√∫mero entero entre 0 y 100
- Las razones deben ser espec√≠ficas y accionables, no gen√©ricas"""

    user_message = f"""REQUERIMIENTO DEL CLIENTE:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
{user_prompt}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
CANDIDATOS PRE-SELECCIONADOS (por similitud sem√°ntica):
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
{chr(10).join(candidatos_texto)}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Analiza estrat√©gicamente y selecciona los {top_k} proyectos m√°s valiosos con razonamiento expl√≠cito."""

    try:
        response = client.chat.completions.create(
            model=MODEL_CHAT,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            response_format={"type": "json_object"}
        )
        
        result_text = response.choices[0].message.content
        
        # Limpiar posibles markdown
        result_text = result_text.replace("```json", "").replace("```", "").strip()
        result = json.loads(result_text)
        
        # Mapear de vuelta a los proyectos originales
        final_ranking = []
        for item in result["top_projects"]:
            candidato_idx = item["candidato_numero"] - 1
            
            if candidato_idx >= len(candidates):
                continue
                
            proj_idx, semantic_score, project = candidates[candidato_idx]
            
            final_ranking.append({
                "project": project,
                "gpt_score": item["score_final"],
                "semantic_score": semantic_score,
                "reasoning": item["razon_principal"],
                "strengths": item.get("fortalezas", []),
                "weaknesses": item.get("debilidades", [])
            })
        
        return final_ranking, result.get("analisis_general", "")
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è GPT-5 re-ranking fall√≥: {e}. Usando orden sem√°ntico como fallback.")
        # Fallback al orden sem√°ntico
        fallback = []
        for _, semantic_score, project in candidates[:top_k]:
            fallback.append({
                "project": project,
                "semantic_score": semantic_score,
                "gpt_score": None,
                "reasoning": "Re-ranking no disponible (usando similitud sem√°ntica)",
                "strengths": [],
                "weaknesses": []
            })
        return fallback, ""


def llm_explain_selection(client: OpenAI, user_prompt: str, ranked_projects: List[Dict[str, Any]]) -> str:
    """Genera explicaci√≥n contextual de la selecci√≥n final"""
    
    bullets = []
    for item in ranked_projects:
        p = item["project"]
        gpt_score = item.get("gpt_score")
        semantic_score = item.get("semantic_score", 0)
        
        score_text = f"GPT-5: {gpt_score}/100" if gpt_score else f"Sem√°ntica: {semantic_score:.1%}"
        
        bullets.append(
            f"- **{p.get('nombre_cliente', 'Sin nombre')}** ({p.get('industria', 'N/A')})\n"
            f"  {p.get('nombre_proyecto', 'N/A')} | {score_text}\n"
            f"  {item.get('reasoning', '')[:150]}...\n"
        )
    
    system_prompt = """Eres un consultor senior de CIS. Genera una explicaci√≥n ejecutiva clara y persuasiva de POR QU√â estos proyectos son los m√°s relevantes.

INSTRUCCIONES:
- Escribe 2-3 p√°rrafos concisos (m√°ximo 150 palabras total)
- Enf√≥cate en conexiones estrat√©gicas y aprendizajes transferibles
- Menciona proyectos por nombre de cliente cuando sea relevante
- Lenguaje profesional pero conversacional
- Sin bullet points ni listas"""

    content = f"""REQUERIMIENTO:
{user_prompt}

PROYECTOS SELECCIONADOS:
{chr(10).join(bullets)}

Explica de manera ejecutiva por qu√© estos son los mejores matches."""

    try:
        r = client.chat.completions.create(
            model=MODEL_CHAT,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": content}
            ],
        )
        return (r.choices[0].message.content or "").strip()
    except Exception as e:
        return f"‚ö†Ô∏è No se pudo generar explicaci√≥n: {e}"


def build_user_prompt(form_data: Dict[str, Any]) -> str:
    """Construye el prompt del usuario desde el formulario"""
    parts = []
    
    parts.append("=== CONTEXTO DEL PROYECTO ===")
    
    if form_data.get("area"):
        parts.append(f"√Årea de enfoque: {form_data['area']}")
    
    if form_data.get("categoria"):
        parts.append(f"Categor√≠a espec√≠fica: {form_data['categoria']}")
    
    if form_data.get("industrias"):
        parts.append(f"Industria(s) del cliente: {', '.join(form_data['industrias'])}")
    
    if form_data.get("objetivo"):
        parts.append("\n=== OBJETIVO PRINCIPAL ===")
        parts.append(form_data['objetivo'])
    
    detalles = []
    
    if form_data.get("duracion"):
        detalles.append(f"Duraci√≥n estimada: {form_data['duracion']}")
    
    if form_data.get("entregables"):
        detalles.append(f"Entregables esperados: {', '.join(form_data['entregables'])}")
    
    if form_data.get("enfoque"):
        detalles.append(f"Enfoque del proyecto: {', '.join(form_data['enfoque'])}")
    
    if detalles:
        parts.append("\n=== DETALLES ADICIONALES ===")
        parts.extend(detalles)
    
    if form_data.get("comentarios"):
        parts.append("\n=== INFORMACI√ìN COMPLEMENTARIA ===")
        parts.append(form_data['comentarios'])
    
    return "\n".join(parts)


def safe_float_conversion(value: Any, default: float = 0.0) -> float:
    """Convierte un valor a float de manera segura"""
    if value is None:
        return default
    try:
        return float(value)
    except (ValueError, TypeError):
        return default


# ========================================
# APLICACI√ìN PRINCIPAL
# ========================================

st.set_page_config(
    page_title="CIS ‚Ä¢ Asistente de Proyectos", 
    page_icon="üéØ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

css_cis()

# Header
st.markdown(
    """
    <div class='cis-header'>
        <h1>üéØ Asistente CIS ¬∑ Recomendador Inteligente con GPT-5</h1>
        <p>Sistema h√≠brido de b√∫squeda sem√°ntica + razonamiento estrat√©gico con IA</p>
    </div>
    """,
    unsafe_allow_html=True
)

# Validaci√≥n de API Key
if not OPENAI_API_KEY:
    st.error("‚ö†Ô∏è Define la variable de entorno OPENAI_API_KEY antes de ejecutar la aplicaci√≥n.")
    st.info("üí° En PowerShell ejecuta: `$env:OPENAI_API_KEY=\"tu-api-key\"`")
    st.stop()

# Inicializaci√≥n
client = OpenAI(api_key=OPENAI_API_KEY)
projects = load_projects(PROJECTS_PATH)

if not projects:
    st.warning("‚ö†Ô∏è No se encontraron proyectos en el archivo JSON")
    st.stop()

st.success(f"‚úÖ Cargados **{len(projects)} proyectos** de la base de datos")

# ========================================
# SIDEBAR - SIMPLIFICADO
# ========================================
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥n")
    
    st.markdown("### üéØ Cantidad de Resultados")
    top_k = st.slider(
        "Top-K",
        min_value=1, 
        max_value=10, 
        value=TOP_K_DEFAULT, 
        step=1,
        help="N√∫mero de proyectos a mostrar en resultados finales"
    )
    
    st.caption("üí° Recomendamos 3-5 proyectos para an√°lisis √≥ptimo")
    
    st.divider()
    
    st.markdown("### üß† Modo de B√∫squeda")
    
    usar_gpt_rerank = st.checkbox(
        "üöÄ Activar Re-Ranking Inteligente (GPT-5)",
        value=True,
        help="GPT-5 analiza y re-ordena los resultados con razonamiento estrat√©gico"
    )
    
    if usar_gpt_rerank:
        st.success("‚úÖ **Modo Avanzado**: GPT-5 razonar√° sobre los mejores matches")
        st.caption(f"üìä Analizar√° top-{CANDIDATE_POOL_SIZE} candidatos sem√°nticos y seleccionar√° los {top_k} m√°s estrat√©gicos")
    else:
        st.info("üìê **Modo B√°sico**: Solo similitud sem√°ntica (embeddings)")
    
    st.divider()
    
    st.markdown("### üìä Ordenamiento Adicional")
    orden = st.radio(
        "Criterio secundario:",
        options=["Score Principal", "Categorizaci√≥n Alfab√©tica"],
        help="Aplica despu√©s del an√°lisis principal"
    )
    
    st.divider()
    
    st.markdown("### ‚ÑπÔ∏è Sobre Esta Herramienta")
    st.markdown("""
    **Sistema H√≠brido:**
    
    1Ô∏è‚É£ **Embeddings** pre-seleccionan candidatos similares
    
    2Ô∏è‚É£ **GPT-5** analiza estrat√©gicamente y re-rankea
    
    3Ô∏è‚É£ **Explicaci√≥n** contextual de por qu√© son relevantes
    
    Resultado: Precisi√≥n superior combinando IA sem√°ntica + razonamiento l√≥gico.
    """)
    
    st.divider()
    
    st.markdown("### üîß Detalles T√©cnicos")
    st.markdown(f"""
    - **Proyectos:** {len(projects)}
    - **Modelo Principal:** {MODEL_CHAT}
    - **Embeddings:** {MODEL_EMB}
    - **Pool de An√°lisis:** {CANDIDATE_POOL_SIZE}
    """)

# ========================================
# INFO BOX
# ========================================
st.markdown(
    """
    <div class="cis-info-box">
        <strong>üìù C√≥mo usar el asistente</strong>
        <p style="margin-top: 0.5rem;">
        Completa el <strong>Bloque 1</strong> (obligatorio) con informaci√≥n sobre tu proyecto. 
        El sistema usar√° <strong>embeddings sem√°nticos</strong> para pre-seleccionar candidatos y luego 
        <strong>GPT-5 analizar√° estrat√©gicamente</strong> cu√°les son los m√°s valiosos para tu caso.
        </p>
    </div>
    """,
    unsafe_allow_html=True
)

# ========================================
# BLOQUE 1: INFORMACI√ìN BASE
# ========================================
st.markdown(
    '<div style="background: rgba(0, 86, 112, 0.2); padding: 1.8rem; border-radius: 14px; '
    'margin: 1.5rem 0; border-left: 6px solid #005670;">'
    '<h3 style="color: #FFFFFF; margin: 0; font-weight: 700; font-size: 1.4rem;">üìã Bloque 1: Informaci√≥n Base (Obligatorio)</h3>'
    '</div>', 
    unsafe_allow_html=True
)

col1, col2 = st.columns(2)

with col1:
    area_seleccionada = st.selectbox(
        "1Ô∏è‚É£ ¬øEn qu√© √°rea se enmarca principalmente el proyecto?",
        options=[""] + AREAS,
        help="Selecciona el √°rea de consultor√≠a principal"
    )

with col2:
    if area_seleccionada:
        categoria_seleccionada = st.selectbox(
            "2Ô∏è‚É£ ¬øCu√°l es la categor√≠a espec√≠fica del proyecto?",
            options=[""] + CATEGORIAS.get(area_seleccionada, []),
            help=f"Categor√≠a dentro de {area_seleccionada}"
        )
    else:
        categoria_seleccionada = None
        st.info("üëÜ Primero selecciona un √°rea")

industrias_seleccionadas = st.multiselect(
    "3Ô∏è‚É£ ¬øCu√°l es el contexto del cliente o industria objetivo?",
    options=INDUSTRIAS,
    help="Puedes seleccionar m√∫ltiples industrias si aplica"
)

objetivo_proyecto = st.text_area(
    "4Ô∏è‚É£ ¬øCu√°l es el objetivo principal del proyecto que est√°s desarrollando?",
    height=150,
    placeholder="Ejemplo: Dise√±ar un modelo de negocio sostenible para incursionar en el mercado de comida preparada, "
                "considerando propuesta de valor, segmentaci√≥n de clientes, an√°lisis competitivo, estructura de costos "
                "y proyecci√≥n financiera a 3 a√±os...",
    help="Describe con el mayor detalle posible. Mientras m√°s espec√≠fico seas, mejores resultados obtendr√°s."
)

st.divider()

# ========================================
# BLOQUE 2: EN DESARROLLO
# ========================================
st.markdown(
    '<div style="background: rgba(242, 0, 52, 0.1); padding: 1.5rem; border-radius: 12px; '
    'margin: 1rem 0; border-left: 5px solid #F20034; border: 2px dashed #F20034;">'
    '<h3 style="color: #FF4D6D; margin: 0 0 0.5rem 0; font-weight: 700;">üöß Bloque 2: Informaci√≥n Adicional (En Desarrollo)</h3>'
    '<p style="color: #E5E7EB; margin: 0; font-size: 1.05rem;">Esta secci√≥n estar√° disponible pr√≥ximamente. Por ahora, el an√°lisis se basa √∫nicamente en la informaci√≥n del Bloque 1.</p>'
    '</div>', 
    unsafe_allow_html=True
)

st.divider()

# ========================================
# BOT√ìN DE B√öSQUEDA
# ========================================
st.markdown("<br>", unsafe_allow_html=True)
search_btn = st.button("üîç Buscar Proyectos Similares con IA", type="primary", use_container_width=True)

# ========================================
# PRECARGA DE EMBEDDINGS
# ========================================
@st.cache_resource(show_spinner="üîÑ Cargando embeddings de proyectos...")
def _embeddings_once(_client: OpenAI, _projects: List[Dict[str, Any]]):
    return ensure_embeddings(_client, _projects)

emb_matrix = _embeddings_once(client, projects)

# ========================================
# PROCESAMIENTO DE B√öSQUEDA
# ========================================
if search_btn:
    # Validaci√≥n
    errores = []
    
    if not area_seleccionada:
        errores.append("‚ùå Selecciona un √°rea (Pregunta 1)")
    
    if not categoria_seleccionada:
        errores.append("‚ùå Selecciona una categor√≠a (Pregunta 2)")
    
    if not industrias_seleccionadas:
        errores.append("‚ùå Selecciona al menos una industria (Pregunta 3)")
    
    if not objetivo_proyecto.strip():
        errores.append("‚ùå Describe el objetivo del proyecto (Pregunta 4)")
    
    if errores:
        for error in errores:
            st.error(error)
        st.warning("‚ö†Ô∏è Por favor completa todos los campos obligatorios del Bloque 1")
    else:
        # Construir datos
        form_data = {
            "area": area_seleccionada,
            "categoria": categoria_seleccionada,
            "industrias": industrias_seleccionadas,
            "objetivo": objetivo_proyecto,
            "duracion": None,
            "entregables": [],
            "enfoque": [],
            "comentarios": ""
        }
        
        user_prompt = build_user_prompt(form_data)
        
        # FASE 1: Pre-selecci√≥n sem√°ntica
        with st.spinner("üîç Fase 1/2: Analizando similitud sem√°ntica con embeddings..."):
            q_vec = embed_texts(client, [user_prompt])[0]
            
            sims = []
            for idx, p in enumerate(projects):
                sim = cosine_sim(q_vec, emb_matrix[idx])
                sims.append((idx, sim, p))
            
            sims.sort(key=lambda x: x[1], reverse=True)
            
            # Determinar pool de candidatos
            pool_size = CANDIDATE_POOL_SIZE if usar_gpt_rerank else top_k
            candidates = sims[:pool_size]
        
        # FASE 2: Re-ranking con GPT (si est√° activado)
        if usar_gpt_rerank:
            with st.spinner(f"üß† Fase 2/2: GPT-5 analizando estrat√©gicamente {len(candidates)} candidatos..."):
                ranked_results, analisis_general = llm_rerank_projects(
                    client, 
                    user_prompt, 
                    candidates, 
                    top_k
                )
            
            # Ordenamiento adicional si se seleccion√≥
            if "Categorizaci√≥n" in orden:
                ranked_results.sort(key=lambda x: (
                    x["project"].get("catalogacion", "ZZZ"),
                    -(x.get("gpt_score") or x.get("semantic_score", 0))
                ))
        else:
            # Modo b√°sico: solo sem√°ntico
            if "Categorizaci√≥n" in orden:
                candidates.sort(key=lambda x: (x[2].get("catalogacion", "ZZZ"), -x[1]))
            
            ranked_results = []
            for idx, semantic_score, project in candidates[:top_k]:
                ranked_results.append({
                    "project": project,
                    "semantic_score": semantic_score,
                    "gpt_score": None,
                    "reasoning": None,
                    "strengths": [],
                    "weaknesses": []
                })
            analisis_general = ""
        
        # FASE 3: Explicaci√≥n contextual
        with st.spinner("üí≠ Generando explicaci√≥n contextual..."):
            why = llm_explain_selection(client, user_prompt, ranked_results)
        
        # Mostrar an√°lisis general (si GPT lo gener√≥)
        if analisis_general and usar_gpt_rerank:
            st.markdown(
                f"""
                <div class='cis-why-box'>
                    <strong>üéØ An√°lisis Estrat√©gico GPT-5</strong>
                    <p>{analisis_general}</p>
                </div>
                """,
                unsafe_allow_html=True
            )
        
        # Mostrar explicaci√≥n contextual
        st.markdown(
            f"""
            <div class='cis-why-box'>
                <strong>üìä ¬øPor qu√© estos proyectos son relevantes?</strong>
                <p>{why}</p>
            </div>
            """,
            unsafe_allow_html=True
        )
        
        # Header de resultados
        modo_texto = "GPT-5 Re-Ranking" if usar_gpt_rerank else "Similitud Sem√°ntica"
        st.markdown(
            f'<div style="background: rgba(242, 0, 52, 0.15); padding: 1.8rem; border-radius: 14px; '
            f'margin: 2rem 0 1.5rem 0; border-left: 6px solid #F20034;">'
            f'<h3 style="color: #FFFFFF; margin: 0; font-weight: 700; font-size: 1.5rem;">'
            f'üìã {len(ranked_results)} Proyecto{"s" if len(ranked_results) > 1 else ""} Seleccionado{"s" if len(ranked_results) > 1 else ""}'
            f'</h3>'
            f'<p style="color: #E5E7EB; margin: 0.5rem 0 0 0; font-size: 1.05rem;">M√©todo: <strong>{modo_texto}</strong></p>'
            f'</div>', 
            unsafe_allow_html=True
        )
        
        # Renderizar resultados
        for idx, item in enumerate(ranked_results, 1):
            p = item["project"]
            gpt_score = item.get("gpt_score")
            semantic_score = item.get("semantic_score", 0)
            reasoning = item.get("reasoning")
            strengths = item.get("strengths", [])
            weaknesses = item.get("weaknesses", [])
            
            nombre_cliente = p.get('nombre_cliente', 'Sin nombre')
            industria = p.get("industria", "N/A")
            nombre_proyecto = p.get("nombre_proyecto", "N/A")
            area_negocio = p.get("area_negocio", "N/A")
            catalogacion = p.get("catalogacion", "N/A")
            anio = p.get("anio", "N/A")
            
            # Card
            st.markdown("<div class='cis-result-card'>", unsafe_allow_html=True)
            
            # T√≠tulo con badge de score
            if gpt_score:
                badge_html = f"<span class='gpt-badge'>üß† GPT-5: {gpt_score}/100</span>"
            else:
                badge_html = f"<span class='gpt-badge'>üìê {semantic_score:.1%}</span>"
            
            st.markdown(
                f"<div class='cis-client-name'>‚ûî {idx}. {nombre_cliente} {badge_html}</div>", 
                unsafe_allow_html=True
            )
            
            # Metadata
            st.markdown(
                f"<div class='cis-meta-item'><strong>üìÅ Proyecto:</strong> {nombre_proyecto}</div>", 
                unsafe_allow_html=True
            )
            st.markdown(
                f"<div class='cis-meta-item'><strong>üè¢ Industria:</strong> {industria}</div>", 
                unsafe_allow_html=True
            )
            st.markdown(
                f"<div class='cis-meta-item'><strong>üéØ √Årea:</strong> {area_negocio} | "
                f"<strong>Tipo:</strong> {catalogacion}</div>", 
                unsafe_allow_html=True
            )
            
            if anio and anio != "N/A":
                st.markdown(
                    f"<div class='cis-meta-item'><strong>üìÖ A√±o:</strong> {anio}</div>", 
                    unsafe_allow_html=True
                )
            
            # Score sem√°ntico adicional (si hay GPT score)
            if gpt_score:
                st.markdown(
                    f"<div class='cis-meta-item'><strong>üìä Similitud Sem√°ntica Base:</strong> "
                    f"<span style='color: #9BB3BC;'>{semantic_score:.1%}</span></div>", 
                    unsafe_allow_html=True
                )
            
            # Razonamiento GPT-5 (si existe)
            if reasoning and usar_gpt_rerank:
                reasoning_html = f"<div class='gpt-reasoning'><strong>üß† Razonamiento GPT-5:</strong><p>{reasoning}</p>"
                
                if strengths:
                    reasoning_html += "<strong style='color: #00D4FF; display: block; margin-top: 0.8rem;'>‚úì Fortalezas:</strong><ul>"
                    for s in strengths:
                        reasoning_html += f"<li>{s}</li>"
                    reasoning_html += "</ul>"
                
                if weaknesses:
                    reasoning_html += "<strong style='color: #FF4D6D; display: block; margin-top: 0.5rem;'>‚ö† Consideraciones:</strong><ul>"
                    for w in weaknesses:
                        reasoning_html += f"<li>{w}</li>"
                    reasoning_html += "</ul>"
                
                reasoning_html += "</div>"
                st.markdown(reasoning_html, unsafe_allow_html=True)
            
            # Propuesta econ√≥mica
            pvp = safe_float_conversion(p.get("pvp"))
            moneda = p.get("moneda", "UF")
            
            if pvp > 0:
                econ_html = (
                    "<div class='cis-economic-box'>"
                    "<strong>üí∞ Propuesta Econ√≥mica:</strong><br>"
                    f"<div style='margin-left: 1rem; margin-top: 0.4rem;'>"
                    f"‚Ä¢ Valor del Proyecto: <strong>{pvp:,.0f} {moneda}</strong>"
                    f"</div>"
                    "</div>"
                )
                st.markdown(econ_html, unsafe_allow_html=True)
            
            # Extracto t√©cnico - OBJETIVOS COMPLETOS
            objetivo_general = (p.get("objetivo_general") or "").strip()
            objetivos_especificos = (p.get("objetivos_especificos") or "").strip()
            
            if objetivo_general or objetivos_especificos:
                excerpt_html = "<div class='cis-excerpt'>"
                
                if objetivo_general:
                    excerpt_html += f"<strong>Objetivo General:</strong><br>{objetivo_general}<br><br>"
                
                if objetivos_especificos:
                    # MOSTRAR COMPLETO (no truncar)
                    excerpt_html += f"<strong>Objetivos Espec√≠ficos:</strong><br>{objetivos_especificos}"
                
                excerpt_html += "</div>"
                st.markdown(excerpt_html, unsafe_allow_html=True)
            
            # Enlaces
            links = []
            if p.get("url_tecnica"):
                links.append(
                    f"<a href='{p['url_tecnica']}' target='_blank'>üìÑ Propuesta T√©cnica</a>"
                )
            if p.get("url_economica"):
                links.append(
                    f"<a href='{p['url_economica']}' target='_blank'>üí∞ Propuesta Econ√≥mica</a>"
                )
            
            if links:
                st.markdown(
                    f"<div class='cis-links'>{''.join(links)}</div>", 
                    unsafe_allow_html=True
                )
            
            st.markdown("</div>", unsafe_allow_html=True)
            st.markdown("<br>", unsafe_allow_html=True)

